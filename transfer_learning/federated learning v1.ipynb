{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from random import random\n",
    "from collections import defaultdict\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torchvision import models\n",
    "import json\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import matplotlib.ticker as ticker \n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.1.48-cp38-cp38-win_amd64.whl (34.9 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\garim\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 467 total benign cancer images.\n",
      "There are 3575 total malignant cancer images.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pt\n",
    "import matplotlib as plt\n",
    "from glob import glob\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt    \n",
    "benign_train = np.array(glob(\"C:/Users/garim/Documents/federatedLearning/data/train/benign/*\"))\n",
    "malignant_train = np.array(glob(\"C:/Users/garim/Documents/federatedLearning/data/train/malignant/*\"))\n",
    "print('There are %d total benign cancer images.' % len(benign_train))\n",
    "print('There are %d total malignant cancer images.' % len(malignant_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device =''\n",
    "if torch.cuda.is_available() :\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"cuda\") \n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4042,)\n"
     ]
    }
   ],
   "source": [
    "# concat the data and make the train and validation images\n",
    "combined_data_train = np.concatenate((benign_train, malignant_train), axis =0)\n",
    "print (combined_data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4042,)\n"
     ]
    }
   ],
   "source": [
    "#generating the labels\n",
    "benign_train_label = np.zeros(len(benign_train))\n",
    "malignant_train_label = np.ones(len(malignant_train)) # we are using 1 for malignant and 0 for benign cancer\n",
    "combined_labels_train = np.concatenate((benign_train_label, malignant_train_label), axis = 0)\n",
    "print (combined_labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/garim/Documents/federatedLearning/data/train/benign\\SOB_B_A-14-22549AB-200-016.png\n"
     ]
    }
   ],
   "source": [
    "print (combined_data_train[0]) # np array of path files to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4042,)\n",
      "(4042,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range (20):\\n    print (X_train[i],\"--->\",Y_train[i],\"--->\", Y_train_encoded[i])\\n#print (X_train[:20],\"--->\", Y_train[:20])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the images in the training np array to avoid overfitting\n",
    "random_array = np.arange(combined_data_train.shape[0])\n",
    "np.random.shuffle(random_array)\n",
    "X_train = combined_data_train[random_array]\n",
    "Y_train = combined_labels_train[random_array]\n",
    "print (X_train.shape)\n",
    "print (Y_train.shape)\n",
    "'''\n",
    "for i in range (20):\n",
    "    print (X_train[i],\"--->\",Y_train[i],\"--->\", Y_train_encoded[i])\n",
    "#print (X_train[:20],\"--->\", Y_train[:20])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4042, 2)\n"
     ]
    }
   ],
   "source": [
    "# convert to one hot encoding\n",
    "Y_train_encoded = np.zeros([combined_data_train.shape[0], 2])\n",
    "print (Y_train_encoded.shape)\n",
    "for i in range(0, len(Y_train)):\n",
    "  if combined_labels_train[i] == 0: #benign  one hot encoding = 1,0\n",
    "    Y_train_encoded[i][0] = 1\n",
    "  else: # malignant one hot encoding = 0,1\n",
    "    Y_train_encoded[i][1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Define a global transformer to appropriately scale images and subsequently convert them to a Tensor.\n",
    "img_size = 224\n",
    "loader = transforms.Compose([\n",
    "  transforms.Resize(img_size),\n",
    "  transforms.CenterCrop(img_size),\n",
    "  transforms.ToTensor(),\n",
    "]) \n",
    "def load_image(filename):\n",
    "    \"\"\"\n",
    "    Simple function to load and preprocess the image.\n",
    "\n",
    "    1. Open the image.\n",
    "    2. Scale/crop it and convert it to a float tensor.\n",
    "    3. Convert it to a variable (all inputs to PyTorch models must be variables).\n",
    "    4. Add another dimension to the start of the Tensor (b/c VGG expects a batch).\n",
    "    5. Move the variable onto the GPU.\n",
    "    \"\"\"\n",
    "    image = Image.open(filename).convert('RGB')\n",
    "    image_tensor = loader(image).float()\n",
    "    image_var = Variable(image_tensor).unsqueeze(0)\n",
    "    #return image_var.cuda()\n",
    "    #print (image_var.shape)\n",
    "    return image_var\n",
    "trial = load_image(combined_data_train[0])\n",
    "print (type(trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pretrained model\n",
    "# modify the pretrained model\n",
    "# vectorize all images by passing through vgg16\n",
    "# visualize\n",
    "# Write custom dataset\n",
    "# write custom neural net\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a pretrained model\n",
    "vgg_model = models.vgg16(pretrained = True)\n",
    "vgg_model.eval()\n",
    "vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = vgg_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify the pretrained model - basically generate the feature map by removing the last layer\n",
    "# saving original number of in features and out features for the last layer\n",
    "original_infeatures = vgg_model.classifier[6].in_features\n",
    "original_outfeatures = vgg_model.classifier[6].out_features\n",
    "#print (original_infeatures)\n",
    "# modifying the model\n",
    "vgg_model.classifier = nn.Sequential(*[vgg_model.classifier[i] for i in range(5)])\n",
    "vgg_model.eval() # remove the dropout for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images vectorized =  0\n",
      "Number of images vectorized =  100\n",
      "Number of images vectorized =  200\n",
      "Number of images vectorized =  300\n",
      "Number of images vectorized =  400\n",
      "Number of images vectorized =  500\n",
      "Number of images vectorized =  600\n",
      "Number of images vectorized =  700\n",
      "Number of images vectorized =  800\n",
      "Number of images vectorized =  900\n",
      "Number of images vectorized =  1000\n",
      "Number of images vectorized =  1100\n",
      "Number of images vectorized =  1200\n",
      "Number of images vectorized =  1300\n",
      "Number of images vectorized =  1400\n",
      "Number of images vectorized =  1500\n",
      "Number of images vectorized =  1600\n",
      "Number of images vectorized =  1700\n",
      "Number of images vectorized =  1800\n",
      "Number of images vectorized =  1900\n",
      "Number of images vectorized =  2000\n",
      "Number of images vectorized =  2100\n",
      "Number of images vectorized =  2200\n",
      "Number of images vectorized =  2300\n",
      "Number of images vectorized =  2400\n",
      "Number of images vectorized =  2500\n",
      "Number of images vectorized =  2600\n",
      "Number of images vectorized =  2700\n",
      "Number of images vectorized =  2800\n",
      "Number of images vectorized =  2900\n",
      "Number of images vectorized =  3000\n",
      "Number of images vectorized =  3100\n",
      "Number of images vectorized =  3200\n",
      "Number of images vectorized =  3300\n",
      "Number of images vectorized =  3400\n",
      "Number of images vectorized =  3500\n",
      "Number of images vectorized =  3600\n",
      "Number of images vectorized =  3700\n",
      "Number of images vectorized =  3800\n",
      "Number of images vectorized =  3900\n",
      "Number of images vectorized =  4000\n"
     ]
    }
   ],
   "source": [
    "# vectorize all images by passing through vgg16\n",
    "#training_vectors = torch.zeros((X_train.shape[0], 4096), device=device)\n",
    "training_vectors = np.zeros((X_train.shape[0], 4096))\n",
    "for i in range(0, X_train.shape[0]):\n",
    "  img = load_image(X_train[i]).to(device)\n",
    "  #img = load_image(X_train[i])\n",
    "  features = vgg_model(img)\n",
    "  training_vectors[i] = features.cpu().detach().numpy()\n",
    "  #print (training_vectors[i].device)\n",
    "  #training_vectors[i] = features.cpu().detach().numpy()\n",
    "  if i%100 ==0:\n",
    "    print (\"Number of images vectorized = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4042, 4096)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "# Write custom dataset\n",
    "# write custom neural net\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat image dataset \n",
    "class ImageDataset(Dataset):\n",
    "  def __init__(self,X,Y):\n",
    "    self.n_samples = X.shape[0]\n",
    "    self.X = torch.from_numpy(X)\n",
    "    self.Y = torch.from_numpy(Y)\n",
    "  def __getitem__(self,index):\n",
    "    return self.X[index], self.Y[index]\n",
    "    \n",
    "  def __len__(self):\n",
    "    return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write custom neural net\n",
    "class Imageclassification(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Imageclassification, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "  def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.sigmoid(out) # We require this if we use BCE LOSS\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "n_inputs = 4096\n",
    "n_hidden = 512\n",
    "n_outputs = 2\n",
    "model = Imageclassification(n_inputs, n_hidden, n_outputs)\n",
    "learning_rate=0.01\n",
    "# loss and optimizer\n",
    "#criterion = nn.MultiLabelSoftMarginLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(training_vectors,Y_train_encoded)\n",
    "dataloader_train = DataLoader(dataset = dataset, batch_size = 50, shuffle = True)\n",
    "dataiter = iter(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.double()\n",
    "outputs = model(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "total_loss = []\n",
    "def train(model, learning_rate=0.01, batch_size=50, epochs=100):\n",
    "    \"\"\"\n",
    "    Training function which takes as input a model, a learning rate and a batch size.\n",
    "  \n",
    "    After completing a full pass over the data, the function exists, and the input model will be trained.\n",
    "    \"\"\"\n",
    "    # -- Your code goes here --\n",
    "    for i in range(0,epochs):\n",
    "        model.train()\n",
    "        for b_index, (featueres, labels) in enumerate(dataloader_train):\n",
    "            #print (featueres.shape)\n",
    "            #print (b_index)\n",
    "            outputs = model(featueres)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            if(b_index)%50 == 0:\n",
    "                print (f'epoch {i+1}/{epochs} Batch {b_index+1} loss {loss}')\n",
    "                total_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100 Batch 1 loss 0.6178126700687341\n",
      "epoch 1/100 Batch 51 loss 0.49449457545441744\n",
      "epoch 2/100 Batch 1 loss 0.40621323052398806\n",
      "epoch 2/100 Batch 51 loss 0.36777174338603474\n",
      "epoch 3/100 Batch 1 loss 0.3286144106946405\n",
      "epoch 3/100 Batch 51 loss 0.4059856129450188\n",
      "epoch 4/100 Batch 1 loss 0.19585818802788338\n",
      "epoch 4/100 Batch 51 loss 0.36733348967696705\n",
      "epoch 5/100 Batch 1 loss 0.28505020640784723\n",
      "epoch 5/100 Batch 51 loss 0.285881886055258\n",
      "epoch 6/100 Batch 1 loss 0.40599161836354086\n",
      "epoch 6/100 Batch 51 loss 0.3659117422771388\n",
      "epoch 7/100 Batch 1 loss 0.28241338015106376\n",
      "epoch 7/100 Batch 51 loss 0.44263853033190287\n",
      "epoch 8/100 Batch 1 loss 0.4088440876735588\n",
      "epoch 8/100 Batch 51 loss 0.20813221046005836\n",
      "epoch 9/100 Batch 1 loss 0.2861567617677198\n",
      "epoch 9/100 Batch 51 loss 0.32810142608067366\n",
      "epoch 10/100 Batch 1 loss 0.24337533602566805\n",
      "epoch 10/100 Batch 51 loss 0.4044005933995203\n",
      "epoch 11/100 Batch 1 loss 0.2822782727050409\n",
      "epoch 11/100 Batch 51 loss 0.4080559019177734\n",
      "epoch 12/100 Batch 1 loss 0.28469992273400085\n",
      "epoch 12/100 Batch 51 loss 0.2864669261740726\n",
      "epoch 13/100 Batch 1 loss 0.19667032384384128\n",
      "epoch 13/100 Batch 51 loss 0.36593117616005216\n",
      "epoch 14/100 Batch 1 loss 0.2863530531847912\n",
      "epoch 14/100 Batch 51 loss 0.4881442441147201\n",
      "epoch 15/100 Batch 1 loss 0.36521938518068003\n",
      "epoch 15/100 Batch 51 loss 0.36721930035943046\n",
      "epoch 16/100 Batch 1 loss 0.32503499181469253\n",
      "epoch 16/100 Batch 51 loss 0.36464930021902303\n",
      "epoch 17/100 Batch 1 loss 0.5269167940210948\n",
      "epoch 17/100 Batch 51 loss 0.32315160206965315\n",
      "epoch 18/100 Batch 1 loss 0.2417479775215242\n",
      "epoch 18/100 Batch 51 loss 0.2806192885766524\n",
      "epoch 19/100 Batch 1 loss 0.4127568413716722\n",
      "epoch 19/100 Batch 51 loss 0.23953995059394387\n",
      "epoch 20/100 Batch 1 loss 0.43516269698667626\n",
      "epoch 20/100 Batch 51 loss 0.4093143895871822\n",
      "epoch 21/100 Batch 1 loss 0.3220896720942268\n",
      "epoch 21/100 Batch 51 loss 0.48774389173204996\n",
      "epoch 22/100 Batch 1 loss 0.40591155475157914\n",
      "epoch 22/100 Batch 51 loss 0.3245390393914039\n",
      "epoch 23/100 Batch 1 loss 0.36536345970077844\n",
      "epoch 23/100 Batch 51 loss 0.4456329361211225\n",
      "epoch 24/100 Batch 1 loss 0.40531375989269536\n",
      "epoch 24/100 Batch 51 loss 0.40572682397315973\n",
      "epoch 25/100 Batch 1 loss 0.5324148789287426\n",
      "epoch 25/100 Batch 51 loss 0.4901267221543895\n",
      "epoch 26/100 Batch 1 loss 0.44215484077515554\n",
      "epoch 26/100 Batch 51 loss 0.28569259012012205\n",
      "epoch 27/100 Batch 1 loss 0.2832867618847944\n",
      "epoch 27/100 Batch 51 loss 0.4396256418974317\n",
      "epoch 28/100 Batch 1 loss 0.3643371565839151\n",
      "epoch 28/100 Batch 51 loss 0.2000334570806769\n",
      "epoch 29/100 Batch 1 loss 0.3582670333396651\n",
      "epoch 29/100 Batch 51 loss 0.44131966435155234\n",
      "epoch 30/100 Batch 1 loss 0.24182415285502423\n",
      "epoch 30/100 Batch 51 loss 0.3680618390764275\n",
      "epoch 31/100 Batch 1 loss 0.3723355257754902\n",
      "epoch 31/100 Batch 51 loss 0.3247291568571126\n",
      "epoch 32/100 Batch 1 loss 0.24797580551734455\n",
      "epoch 32/100 Batch 51 loss 0.3230556724598755\n",
      "epoch 33/100 Batch 1 loss 0.439241426119102\n",
      "epoch 33/100 Batch 51 loss 0.3151741542782717\n",
      "epoch 34/100 Batch 1 loss 0.27838786103786284\n",
      "epoch 34/100 Batch 51 loss 0.29474609995362117\n",
      "epoch 35/100 Batch 1 loss 0.3274417757111848\n",
      "epoch 35/100 Batch 51 loss 0.3561836249136859\n",
      "epoch 36/100 Batch 1 loss 0.234616290127767\n",
      "epoch 36/100 Batch 51 loss 0.48763493671487657\n",
      "epoch 37/100 Batch 1 loss 0.48251455092428097\n",
      "epoch 37/100 Batch 51 loss 0.2378229390780996\n",
      "epoch 38/100 Batch 1 loss 0.4115231822860721\n",
      "epoch 38/100 Batch 51 loss 0.5302985515333439\n",
      "epoch 39/100 Batch 1 loss 0.28605200812977977\n",
      "epoch 39/100 Batch 51 loss 0.32693861369307803\n",
      "epoch 40/100 Batch 1 loss 0.40186834922730424\n",
      "epoch 40/100 Batch 51 loss 0.32209089178394656\n",
      "epoch 41/100 Batch 1 loss 0.3542305755290938\n",
      "epoch 41/100 Batch 51 loss 0.3274746832276652\n",
      "epoch 42/100 Batch 1 loss 0.31905841849499067\n",
      "epoch 42/100 Batch 51 loss 0.4498217318175085\n",
      "epoch 43/100 Batch 1 loss 0.35883850604465267\n",
      "epoch 43/100 Batch 51 loss 0.27113891428106407\n",
      "epoch 44/100 Batch 1 loss 0.39612284758187116\n",
      "epoch 44/100 Batch 51 loss 0.5696253705251453\n",
      "epoch 45/100 Batch 1 loss 0.2548592115433719\n",
      "epoch 45/100 Batch 51 loss 0.44800541187688486\n",
      "epoch 46/100 Batch 1 loss 0.365030954007722\n",
      "epoch 46/100 Batch 51 loss 0.4795428922313282\n",
      "epoch 47/100 Batch 1 loss 0.36796472438651706\n",
      "epoch 47/100 Batch 51 loss 0.32063024112458793\n",
      "epoch 48/100 Batch 1 loss 0.36608531925511484\n",
      "epoch 48/100 Batch 51 loss 0.33257537243165225\n",
      "epoch 49/100 Batch 1 loss 0.47974973976960933\n",
      "epoch 49/100 Batch 51 loss 0.4484422494648173\n",
      "epoch 50/100 Batch 1 loss 0.36242219368590567\n",
      "epoch 50/100 Batch 51 loss 0.5529101896680539\n",
      "epoch 51/100 Batch 1 loss 0.3234378379403995\n",
      "epoch 51/100 Batch 51 loss 0.27889931266392876\n",
      "epoch 52/100 Batch 1 loss 0.3681187066497099\n",
      "epoch 52/100 Batch 51 loss 0.36712326938498924\n",
      "epoch 53/100 Batch 1 loss 0.36705994204658543\n",
      "epoch 53/100 Batch 51 loss 0.6052993856109984\n",
      "epoch 54/100 Batch 1 loss 0.31658859812851076\n",
      "epoch 54/100 Batch 51 loss 0.48260967377971076\n",
      "epoch 55/100 Batch 1 loss 0.6496552873812553\n",
      "epoch 55/100 Batch 51 loss 0.39922592366679227\n",
      "epoch 56/100 Batch 1 loss 0.4368242985552986\n",
      "epoch 56/100 Batch 51 loss 0.25559331988663514\n",
      "epoch 57/100 Batch 1 loss 0.433636890719902\n",
      "epoch 57/100 Batch 51 loss 0.32310275278322775\n",
      "epoch 58/100 Batch 1 loss 0.5343704694118033\n",
      "epoch 58/100 Batch 51 loss 0.273246405062509\n",
      "epoch 59/100 Batch 1 loss 0.32001294052179785\n",
      "epoch 59/100 Batch 51 loss 0.49273171103421903\n",
      "epoch 60/100 Batch 1 loss 0.40091486371790835\n",
      "epoch 60/100 Batch 51 loss 0.28711998832158564\n",
      "epoch 61/100 Batch 1 loss 0.3304029000084591\n",
      "epoch 61/100 Batch 51 loss 0.3584221917924726\n",
      "epoch 62/100 Batch 1 loss 0.28065950424396724\n",
      "epoch 62/100 Batch 51 loss 0.28413363864929536\n",
      "epoch 63/100 Batch 1 loss 0.3263996907457446\n",
      "epoch 63/100 Batch 51 loss 0.360922120591169\n",
      "epoch 64/100 Batch 1 loss 0.4017273956411358\n",
      "epoch 64/100 Batch 51 loss 0.3578837535465291\n",
      "epoch 65/100 Batch 1 loss 0.3674223492186627\n",
      "epoch 65/100 Batch 51 loss 0.39793150597023513\n",
      "epoch 66/100 Batch 1 loss 0.43796198525008506\n",
      "epoch 66/100 Batch 51 loss 0.4906060950051767\n",
      "epoch 67/100 Batch 1 loss 0.24280446174510217\n",
      "epoch 67/100 Batch 51 loss 0.3227323010467378\n",
      "epoch 68/100 Batch 1 loss 0.36874648644372976\n",
      "epoch 68/100 Batch 51 loss 0.4470368449572788\n",
      "epoch 69/100 Batch 1 loss 0.4291136125960853\n",
      "epoch 69/100 Batch 51 loss 0.29845873903582154\n",
      "epoch 70/100 Batch 1 loss 0.37088060004647777\n",
      "epoch 70/100 Batch 51 loss 0.3328524055710127\n",
      "epoch 71/100 Batch 1 loss 0.278283911139376\n",
      "epoch 71/100 Batch 51 loss 0.511510739274494\n",
      "epoch 72/100 Batch 1 loss 0.44308219443202235\n",
      "epoch 72/100 Batch 51 loss 0.3129621708533582\n",
      "epoch 73/100 Batch 1 loss 0.2753369498473204\n",
      "epoch 73/100 Batch 51 loss 0.32235802930494606\n",
      "epoch 74/100 Batch 1 loss 0.3649373184197752\n",
      "epoch 74/100 Batch 51 loss 0.36993029332095534\n",
      "epoch 75/100 Batch 1 loss 0.34711588694938683\n",
      "epoch 75/100 Batch 51 loss 0.3594627477338579\n",
      "epoch 76/100 Batch 1 loss 0.32298701706455446\n",
      "epoch 76/100 Batch 51 loss 0.43269244568712273\n",
      "epoch 77/100 Batch 1 loss 0.4431855630457363\n",
      "epoch 77/100 Batch 51 loss 0.17344213967045313\n",
      "epoch 78/100 Batch 1 loss 0.3330871537400906\n",
      "epoch 78/100 Batch 51 loss 0.314795877574845\n",
      "epoch 79/100 Batch 1 loss 0.29083447988068134\n",
      "epoch 79/100 Batch 51 loss 0.45379376523981935\n",
      "epoch 80/100 Batch 1 loss 0.3325533675331846\n",
      "epoch 80/100 Batch 51 loss 0.44037003055277474\n",
      "epoch 81/100 Batch 1 loss 0.3541137753478496\n",
      "epoch 81/100 Batch 51 loss 0.5424030914855471\n",
      "epoch 82/100 Batch 1 loss 0.4794062238464655\n",
      "epoch 82/100 Batch 51 loss 0.31141870094964774\n",
      "epoch 83/100 Batch 1 loss 0.37174818417230626\n",
      "epoch 83/100 Batch 51 loss 0.284159652871153\n",
      "epoch 84/100 Batch 1 loss 0.44204832211358197\n",
      "epoch 84/100 Batch 51 loss 0.4375649480556652\n",
      "epoch 85/100 Batch 1 loss 0.519590556983298\n",
      "epoch 85/100 Batch 51 loss 0.4303871315824663\n",
      "epoch 86/100 Batch 1 loss 0.3303733159587709\n",
      "epoch 86/100 Batch 51 loss 0.2536760709446235\n",
      "epoch 87/100 Batch 1 loss 0.4743612820410707\n",
      "epoch 87/100 Batch 51 loss 0.23949610136026117\n",
      "epoch 88/100 Batch 1 loss 0.5838488968529983\n",
      "epoch 88/100 Batch 51 loss 0.2838698692903606\n",
      "epoch 89/100 Batch 1 loss 0.29469918950913576\n",
      "epoch 89/100 Batch 51 loss 0.3129058157673419\n",
      "epoch 90/100 Batch 1 loss 0.4337332149832312\n",
      "epoch 90/100 Batch 51 loss 0.36347635472715\n",
      "epoch 91/100 Batch 1 loss 0.35549188813373933\n",
      "epoch 91/100 Batch 51 loss 0.4820682521711373\n",
      "epoch 92/100 Batch 1 loss 0.32761208030822686\n",
      "epoch 92/100 Batch 51 loss 0.32602312574781905\n",
      "epoch 93/100 Batch 1 loss 0.4427131097003189\n",
      "epoch 93/100 Batch 51 loss 0.40919429525024403\n",
      "epoch 94/100 Batch 1 loss 0.3676507062909306\n",
      "epoch 94/100 Batch 51 loss 0.4917749292790725\n",
      "epoch 95/100 Batch 1 loss 0.3137564199951958\n",
      "epoch 95/100 Batch 51 loss 0.5875583722279493\n",
      "epoch 96/100 Batch 1 loss 0.24151752825207626\n",
      "epoch 96/100 Batch 51 loss 0.35983231160516094\n",
      "epoch 97/100 Batch 1 loss 0.37424828160534396\n",
      "epoch 97/100 Batch 51 loss 0.35678426346619135\n",
      "epoch 98/100 Batch 1 loss 0.41908836782361036\n",
      "epoch 98/100 Batch 51 loss 0.4311760603014364\n",
      "epoch 99/100 Batch 1 loss 0.37268547579884265\n",
      "epoch 99/100 Batch 51 loss 0.3607051654862242\n",
      "epoch 100/100 Batch 1 loss 0.4887922011180116\n",
      "epoch 100/100 Batch 51 loss 0.37303738001799125\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
